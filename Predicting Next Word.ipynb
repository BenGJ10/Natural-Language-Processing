{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72fdf444-bf5c-4bbd-a4b8-6bc49ef32370",
   "metadata": {},
   "source": [
    "# Predicting Next Word using N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d446c0a0-87b7-4c4f-9e6e-99adb677b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import nltk\n",
    "from nltk import bigrams, trigrams\n",
    "from nltk.corpus import reuters\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1302a2f-eedb-4e32-b2bd-587e85eb2be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /Users/bengj/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/bengj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/bengj/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK resources\n",
    "\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aef975d4-4342-4ca6-955f-ed5c05c8050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "\n",
    "words = nltk.word_tokenize(' '.join(reuters.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22a150ba-cc67-433d-a59e-4dd4ee64f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trigrams\n",
    "\n",
    "tri_grams = list(trigrams(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7704a045-03a5-4a3e-9be1-e8890f8b5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a trigram model\n",
    "\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a54c470-348f-4278-810d-80cda76d839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count frequency of co-occurrence\n",
    "# It shows often w3 follows w1 and w2\n",
    "# This loop counts the occurrences of each third word (w3) given a word pair (w1, w2)\n",
    "\n",
    "for w1, w2, w3 in tri_grams:\n",
    "    model[(w1, w2)][w3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a84db75-a1c6-4f2d-8189-af05fe453f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the counts into probabilities\n",
    "# For each bigram (w1, w2), this converts the count of each possible w3 into a probability\n",
    "\n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb15b256-1450-44f6-81c0-00dcf5aa13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the next word\n",
    "# Takes a bigram (w1, w2) and uses the trigram model to find the most probable third word.\n",
    "\n",
    "def predict_next_word(w1, w2):\n",
    "    next_word = model[w1, w2]\n",
    "    if(next_word):\n",
    "        predicted_word = max(next_word, key = next_word.get) # Choose the most likely word to occur next\n",
    "        return predicted_word\n",
    "    else:\n",
    "        return \"No prediction available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "192f4e4e-3c3e-4af9-8fa5-4e748159ff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word:  sure\n"
     ]
    }
   ],
   "source": [
    "print(\"Next word: \", predict_next_word('I', 'am'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1d14edd-1422-45b5-bbc3-92fdc617f719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word:  No prediction available\n"
     ]
    }
   ],
   "source": [
    "print(\"Next word: \", predict_next_word('Let', 'me'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69127127-9c6e-414f-a12e-7a03a5fd11d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word:  of\n"
     ]
    }
   ],
   "source": [
    "print(\"Next word: \", predict_next_word('in', 'front'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887df62-4592-4d64-b292-39dd7d918f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
